{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f09583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from api_keys import rapid_api_key\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5b5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temperature_data(weather_data):\n",
    "    temperature_data = []\n",
    "    processed_entries = set()  # Keep track of processed entries\n",
    "    \n",
    "    # Extract temperature data for December, January, and February\n",
    "    for data_point in weather_data['data']:\n",
    "        date = data_point['date']\n",
    "        tavg = data_point.get('tavg')\n",
    "        tmin = data_point.get('tmin')\n",
    "        tmax = data_point.get('tmax')\n",
    "        \n",
    "        # Check if the entry is a duplicate based on date\n",
    "        if date in processed_entries:\n",
    "            continue\n",
    "        \n",
    "        # Check if all temperature values are None\n",
    "        if tavg is None and tmin is None and tmax is None:\n",
    "            continue\n",
    "\n",
    "        # If any of the temperature values is None, use the available values\n",
    "        if tavg is None:\n",
    "            tavg = (tmin + tmax) / 2 if tmin is not None and tmax is not None else tmin or tmax\n",
    "\n",
    "        # If tmin is None, use tavg instead\n",
    "        if tmin is None:\n",
    "            tmin = tavg\n",
    "\n",
    "        # If tmax is None, use tavg instead\n",
    "        if tmax is None:\n",
    "            tmax = tavg\n",
    "        \n",
    "        # Extract month from date\n",
    "        month = int(date.split('-')[1])\n",
    "        \n",
    "        # Check if month is December, January, or February\n",
    "        if month in [12, 1, 2]:\n",
    "            # Append the processed entry to temperature_data\n",
    "            temperature_data.append({\n",
    "                'date': date,\n",
    "                'tavg': tavg,\n",
    "                'tmin': tmin,\n",
    "                'tmax': tmax\n",
    "            })\n",
    "\n",
    "            # Add the entry to the processed set\n",
    "            processed_entries.add(date)\n",
    "    \n",
    "    return temperature_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac2fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the API function to pull down the weather data. Input Lat/lon of the requested city to get the weather data.\n",
    "#make sure to set up your api_keys file before running this function\n",
    "def get_weather_data(lat, lon):\n",
    "    url = \"https://meteostat.p.rapidapi.com/point/daily\"\n",
    "\n",
    "    querystring = {\n",
    "        \"lat\": str(lat),\n",
    "        \"lon\": str(lon),\n",
    "        \"start\": \"2010-12-01\",\n",
    "        \"end\": \"2020-02-29\",\n",
    "        \"units\": 'imperial'\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": rapid_api_key,\n",
    "        \"X-RapidAPI-Host\": \"meteostat.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    weather_data = response.json()\n",
    "\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679b82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for conversion and export\n",
    "def export_data_to_json(data, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "def export_datasets(datasets):\n",
    "    data_folder = 'data'\n",
    "    subfolder = 'weather'\n",
    "\n",
    "    # Create 'data' folder if it doesn't exist\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "\n",
    "    # Create 'weather' subfolder if it doesn't exist\n",
    "    weather_folder = os.path.join(data_folder, subfolder)\n",
    "    if not os.path.exists(weather_folder):\n",
    "        os.makedirs(weather_folder)\n",
    "\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        filename = os.path.join(weather_folder, f\"{dataset_name}_data.json\")\n",
    "        export_data_to_json(dataset, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8c069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "la = get_weather_data(34, 118)\n",
    "chi = get_weather_data(41, 87)\n",
    "detroit = get_weather_data(42, 83)\n",
    "milwaukee = get_weather_data(43, 87)\n",
    "nyc = get_weather_data(40, -73)\n",
    "columbus = get_weather_data(40, -83)\n",
    "philly = get_weather_data(39, -75)\n",
    "newark = get_weather_data(40, -74)\n",
    "houston = get_weather_data(29, -95)\n",
    "indianapolis = get_weather_data(39, -86)\n",
    "milwaukee = get_weather_data(43, -87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e46882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data\n",
    "la_data = extract_temperature_data(la)\n",
    "nyc_data = extract_temperature_data(nyc)\n",
    "chi_data = extract_temperature_data(chi)\n",
    "detroit_data = extract_temperature_data(detroit)\n",
    "columbus_oh_data = extract_temperature_data(columbus)\n",
    "philly_data = extract_temperature_data(philly)\n",
    "newark_data = extract_temperature_data(newark)\n",
    "houston_data = extract_temperature_data(houston)\n",
    "indianapolis_data = extract_temperature_data(indianapolis)\n",
    "milwaukee_data = extract_temperature_data(milwaukee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918adef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold all datasets to export\n",
    "datasets = {\n",
    "    'Los Angeles': la_data,\n",
    "    'New York City': nyc_data,\n",
    "    'Chicago': chi_data,\n",
    "    'Detroit': detroit_data,\n",
    "    'Columbus': columbus_oh_data,\n",
    "    'Philadelphia': philly_data,\n",
    "    'Newark': newark_data,\n",
    "    'Houston': houston_data,\n",
    "    'Indianapolis': indianapolis_data,\n",
    "    'Milwaukee': milwaukee_data\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc4e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097caebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
